maxEE = c(2,2)
} else {
maxEE <- as.numeric(strsplit(maxEE,',')[[1]])
}
if (is.null(minLen)||minLen == '') {
minLen=75
} else {
minLen = as.numeric(minLen)
}
# Parameters for Denoising
if (is.null(max_consist)||max_consist == '') {
max_consist=20
} else {
max_consist = as.numeric(max_consist)
}
if (is.null(omega_a)||omega_a == '') {
omega_a=1e-40
} else {
omega_a = as.numeric(omega_a)
}
#Parameters for merging
if (is.null(justConcatenate)||justConcatenate == '') {
justConcatenate = TRUE
} else {
justConcatenate = as.logical(as.numeric(justConcatenate))
}
} else {
stop("Please provide valid option for the '--class' argument")
}
#Output parameters
if (dirname(output_filename) != ".") {
output_filename <- output_filename
} else {
output_filename <- paste0(work_dir, "/", output_filename)
}
#Datatable to summarize parmeters
parameter_df <- data.frame(maxEE=maxEE,
trimRight=trimRight,
minLen=minLen,
truncQ=truncQ,
matchIDs=matchIDs,
max_consist=max_consist,
randomize=randomize,
selfConsist=selfConsist,
OMEGA_A=omega_a,
justConcatenate=justConcatenate)
print(parameter_df)
# List files and sample names
if (length(fnFs) == 0 || length(fnFs) != length(fnRs)) {
stop("fastq files incomplete or not found")
}
# Plot Quality profiles before filtering
lapply(fnFs, qprofile, work_dir)
lapply(fnRs, qprofile, work_dir)
########################################
#                DADA2                 #
########################################
# Create paths for filtered fastq
filtFs <- file.path(work_dir, "filtered", paste0(sample.names, "_filt_R1.fastq.gz"))
filtRs <- file.path(work_dir, "filtered", paste0(sample.names, "_filt_R2.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
# Filter read
if (filter == TRUE) {
print("filtering samples...")
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs,
maxN=0, maxEE=maxEE, trimRight=trimRight, truncQ=truncQ, minLen=minLen,
rm.phix=TRUE, compress=TRUE, multithread=TRUE, verbose=TRUE,
matchIDs=matchIDs)
print("filtering done!")
} else {
print("skipping filter except mandatory removal of N's... ")
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncQ=c(0,0), maxN=0, rm.phix=TRUE,
compress=TRUE, multithread=TRUE, verbose=TRUE, matchIDs=matchIDs)
}
# Report and Correct for samples with zero reads after filter
zeros <- row.names(out)[out[,2] == 0]
write.table(zeros, paste0(work_dir, "/zeroReadSamples.txt"), sep = "\t", quote = FALSE)
filtFs <- filtFs[out[,2] != 0]
filtRs <- filtRs[out[,2] != 0]
sample.names <- sample.names[out[,2] != 0]
# Update Out table
out <- out[(out[,2] != 0),]
#Compute the error model
print("starting error model learning for forward reads...")
errF <- learnErrors(filtFs, multithread=TRUE, verbose=2, randomize=randomize, MAX_CONSIST=max_consist)
print("starting error model learning for reverse reads...")
errR <- learnErrors(filtRs, multithread=TRUE, verbose=2, randomize=randomize, MAX_CONSIST=max_consist)
#Plot the Errors
pdf(paste0(work_dir,"/errF.pdf"))
try(print(plotErrors(errF, nominalQ=TRUE)), silent = TRUE)
dev.off()
pdf(paste0(work_dir,"/errR.pdf"))
try(print(plotErrors(errR, nominalQ=TRUE)), silent = TRUE)
dev.off()
#DeReplicate the reads
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
#Run core DADA2 algorithm
print("starting dada2 for forward reads...")
dadaFs <- dada(derepFs, err=errF, selfConsist=selfConsist, multithread=TRUE, verbose=TRUE, OMEGA_A=omega_a)
print("starting dada2 for reverse reads...")
dadaRs <- dada(derepRs, err=errR, selfConsist=selfConsist, multithread=TRUE, verbose=TRUE, OMEGA_A=omega_a)
# Merge reads
print("merging paird ends...")
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE, justConcatenate=justConcatenate, trimOverhang = TRUE)
#Generate sequence table
print("generating sequence table...")
seqtab <- makeSequenceTable(mergers)
print("Number of sequences in table")
print(dim(seqtab))
# Inspect distribution of sequence lengths
print(table(nchar(getSequences(seqtab))))
#Remove Chimeras
if(bimera) {
print("identifying bimeric sequences...")
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
print("Number of non-bimeric sequences:")
print(dim(seqtab.nochim)[2])
print("Percentage of reads which are non-bimeric:")
print(sum(seqtab.nochim)/sum(seqtab))
bimeras <- !(colnames(seqtab) %in% colnames(seqtab.nochim))
write.table(data.frame(sequence = colnames(seqtab), bimera = bimeras), file=paste0(work_dir,"/ASVBimeras.txt"),
quote=FALSE, sep="\t", row.names=FALSE)
} else {
print("skipping Bimera identification..")
}
# Track reads through the pipeline
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
# sink summary from stdout to a file
sink(paste0(work_dir,"/reads_summary.txt"))
print(track)
sink()
#Show the barplot of length distribution
pdf(paste0(work_dir,"/sequences_barplot.pdf"))
print(barplot(table(nchar(getSequences(seqtab)))))
dev.off()
#Generate output: sequence table to a tsv
write.table(seqtab, file=output_filename, quote = FALSE, sep = "\t")
# Save Run as R workspace image (Optional)
if (is.null(save_run)||save_run == '') {
print("--save_run not found or empty. skip saving Rdata image to a file")
} else {
save.image(paste0(work_dir,"/",save_run))
}
lapply(sample.names, match_report_table, work_dir, derepFs, derepRs, dadaFs, dadaRs)
lapply(sample.names, match_report_table, work_dir, derepFs, derepRs, dadaFs, dadaRs)
getwd()
data_dir = "/Users/jorgeamaya/Desktop/Broad_Test/amplicon_decontamination_pipeline/Report/Merge/"
out_dir ="/Users/jorgeamaya/Desktop/Broad_Test/amplicon_decontamination_pipeline/Report/"
if (!require("viridis")) {
install.packages("viridis", repos="http://cran.rstudio.com/")
library("viridis")
}
mergedata <- read.csv(file.path(data_dir, "bbmergefields.tsv"), sep = "\t", header = TRUE)
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
mergedata = mergedata[mergedata$SampleID %in% samples_order,]
mergedata_join = subset(mergedata, select = c(3, 5, 7))
rownames(mergedata_join) = mergedata$SampleID
color_vector = viridis(nrow(t(as.matrix(mergedata_join))), option = "D")
mergedata_join <- mergedata_join[, order(colSums(mergedata_join),
decreasing = TRUE)]
mergedata_join <- mergedata_join[order(-mergedata_join[,1],
-mergedata_join[,2],
-mergedata_join[,3]),]
mergedata_per = subset(mergedata, select = c(4, 6, 8))
rownames(mergedata_per) = mergedata$SampleID
mergedata_per <- mergedata_per[, order(colSums(mergedata_per),
decreasing = TRUE)]
mergedata_per <- mergedata_per[order(-mergedata_per[, 1],
-mergedata_per[, 2],
-mergedata_per[, 3]),]
#Add discarded count AFTER the columns have been organized
rownames(mergedata) = mergedata$SampleID
mergedata = mergedata[rownames(mergedata_join), ]
mergedata_join$Discarded = mergedata$Pairs - mergedata$Joined - mergedata$Ambiguous - mergedata$No_Solution
mergedata_per$DiscardedP = 100 - mergedata_per$JoinedP - mergedata_per$AmbiguousP - mergedata_per$No_SolutionP
col_order = c("Joined", "Ambiguous", "No_Solution", "Discarded")
col_order_p = c("JoinedP", "AmbiguousP", "No_SolutionP", "DiscardedP")
mergedata_join = mergedata_join[, col_order]
mergedata_per = mergedata_per[, col_order_p]
pdf(file.path(out_dir, "BBmerge_performance_absolute_report.pdf"), width = 12)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_join)),
col = c(color_vector, "red"),
border = NA,
ylab = "Reads Count",
xlab = "",
main = "BBMerge performance - Absolute",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Joined", "Ambiguous", "No Solution", "Discarded"),
fill = c(color_vector, "red"),
bty = "n",
cex = 1
)
dev.off()
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_join)),
col = c(color_vector, "red"),
border = NA,
ylab = "Reads Count",
xlab = "",
main = "BBMerge performance - Absolute",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Joined", "Ambiguous", "No Solution", "Discarded"),
fill = c(color_vector, "red"),
bty = "n",
cex = 1
)
dev.off()
pdf(file.path(out_dir, "BBmerge_performance_absolute_report.pdf"), width = 12)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_join)),
col = c(color_vector, "red"),
border = NA,
ylab = "Reads Count",
xlab = "",
main = "BBMerge performance - Absolute",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mergedata_join
data_dir = "/Users/jorgeamaya/Desktop/Broad_Test/amplicon_decontamination_pipeline/Report/Merge/"
out_dir ="/Users/jorgeamaya/Desktop/Broad_Test/amplicon_decontamination_pipeline/Report/"
if (!require("viridis")) {
install.packages("viridis", repos="http://cran.rstudio.com/")
library("viridis")
}
mergedata <- read.csv(file.path(data_dir, "bbmergefields.tsv"), sep = "\t", header = TRUE)
mergedata
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
samples_order
View(mergedata)
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
mergedata = mergedata[mergedata$SampleID %in% samples_order,]
mergedata <- read.csv(file.path(data_dir, "bbmergefields.tsv"), sep = "\t", header = TRUE)
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
mergedata = mergedata[mergedata$SampleID %in% samples_order,]
mergedata$SampleID = gsub("-", "_", mergedata$SampleID)
mergedata_join = subset(mergedata, select = c(3, 5, 7))
rownames(mergedata_join) = mergedata$SampleID
color_vector = viridis(nrow(t(as.matrix(mergedata_join))), option = "D")
mergedata_join <- mergedata_join[, order(colSums(mergedata_join),
decreasing = TRUE)]
mergedata_join <- mergedata_join[order(-mergedata_join[,1],
-mergedata_join[,2],
-mergedata_join[,3]),]
mergedata_per = subset(mergedata, select = c(4, 6, 8))
rownames(mergedata_per) = mergedata$SampleID
mergedata_per <- mergedata_per[, order(colSums(mergedata_per),
decreasing = TRUE)]
mergedata_per <- mergedata_per[order(-mergedata_per[, 1],
-mergedata_per[, 2],
-mergedata_per[, 3]),]
#Add discarded count AFTER the columns have been organized
rownames(mergedata) = mergedata$SampleID
mergedata = mergedata[rownames(mergedata_join), ]
mergedata_join$Discarded = mergedata$Pairs - mergedata$Joined - mergedata$Ambiguous - mergedata$No_Solution
mergedata_per$DiscardedP = 100 - mergedata_per$JoinedP - mergedata_per$AmbiguousP - mergedata_per$No_SolutionP
col_order = c("Joined", "Ambiguous", "No_Solution", "Discarded")
col_order_p = c("JoinedP", "AmbiguousP", "No_SolutionP", "DiscardedP")
mergedata_join = mergedata_join[, col_order]
mergedata_per = mergedata_per[, col_order_p]
mergedata_join
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
mergedata = mergedata[mergedata$SampleID %in% samples_order,]
mergedata$SampleID = gsub("-", "_", mergedata$SampleID)
mergedata <- read.csv(file.path(data_dir, "bbmergefields.tsv"), sep = "\t", header = TRUE)
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
mergedata = mergedata[mergedata$SampleID %in% samples_order,]
mergedata$SampleID = gsub("-", "_", mergedata$SampleID)
mergedata_join = subset(mergedata, select = c(3, 5, 7))
rownames(mergedata_join) = mergedata$SampleID
mergedata_join
mergedata
mergedata <- read.csv(file.path(data_dir, "bbmergefields.tsv"), sep = "\t", header = TRUE)
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
samples_order
mergedata <- read.csv(file.path(data_dir, "bbmergefields.tsv"), sep = "\t", header = TRUE)
mergedata$SampleID = gsub("-", "_", mergedata$SampleID)
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
mergedata = mergedata[mergedata$SampleID %in% samples_order,]
mergedata
mergedata_join = subset(mergedata, select = c(3, 5, 7))
rownames(mergedata_join) = mergedata$SampleID
color_vector = viridis(nrow(t(as.matrix(mergedata_join))), option = "D")
mergedata_join <- mergedata_join[, order(colSums(mergedata_join),
decreasing = TRUE)]
mergedata_join <- mergedata_join[order(-mergedata_join[,1],
-mergedata_join[,2],
-mergedata_join[,3]),]
mergedata_join
mergedata <- read.csv(file.path(data_dir, "bbmergefields.tsv"), sep = "\t", header = TRUE)
mergedata$SampleID = gsub("-", "_", mergedata$SampleID)
#Subset the table to the desired experiments
samples_order = read.csv(file.path(dirname(dirname(data_dir)), "Data", "present.csv"), sep = ",", header = FALSE)$V1
mergedata = mergedata[mergedata$SampleID %in% samples_order,]
mergedata_join = subset(mergedata, select = c(3, 5, 7))
rownames(mergedata_join) = mergedata$SampleID
color_vector = viridis(nrow(t(as.matrix(mergedata_join))), option = "D")
mergedata_join <- mergedata_join[, order(colSums(mergedata_join),
decreasing = TRUE)]
mergedata_join <- mergedata_join[order(-mergedata_join[,1],
-mergedata_join[,2],
-mergedata_join[,3]),]
mergedata_per = subset(mergedata, select = c(4, 6, 8))
rownames(mergedata_per) = mergedata$SampleID
mergedata_per <- mergedata_per[, order(colSums(mergedata_per),
decreasing = TRUE)]
mergedata_per <- mergedata_per[order(-mergedata_per[, 1],
-mergedata_per[, 2],
-mergedata_per[, 3]),]
#Add discarded count AFTER the columns have been organized
rownames(mergedata) = mergedata$SampleID
mergedata = mergedata[rownames(mergedata_join), ]
mergedata_join$Discarded = mergedata$Pairs - mergedata$Joined - mergedata$Ambiguous - mergedata$No_Solution
mergedata_per$DiscardedP = 100 - mergedata_per$JoinedP - mergedata_per$AmbiguousP - mergedata_per$No_SolutionP
col_order = c("Joined", "Ambiguous", "No_Solution", "Discarded")
col_order_p = c("JoinedP", "AmbiguousP", "No_SolutionP", "DiscardedP")
mergedata_join = mergedata_join[, col_order]
mergedata_per = mergedata_per[, col_order_p]
mergedata_join
pdf(file.path(out_dir, "BBmerge_performance_absolute_report.pdf"), width = 12)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_join)),
col = c(color_vector, "red"),
border = NA,
ylab = "Reads Count",
xlab = "",
main = "BBMerge performance - Absolute",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Joined", "Ambiguous", "No Solution", "Discarded"),
fill = c(color_vector, "red"),
bty = "n",
cex = 1
)
dev.off()
pdf(file.path(out_dir, "BBmerge_performance_percentage_report.pdf"), width = 12)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_per)),
col = c(color_vector, "red"),
border = NA,
ylab = "Reads Percentage",
xlab = "",
main = "BBMerge performance - Percentage",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Joined", "Ambiguous", "No Solution", "Discarded"),
fill = c(color_vector, "red"),
bty = "n",
cex = 1
)
dev.off()
mergedata_join <- mergedata_join[order(-mergedata_join[, 4]), ]
pdf(file.path(out_dir, "BBmerge_performace_absolute_discarded.pdf"), width = 12)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_join)[,4]),
col = "red",
border = NA,
ylab = "Reads Count",
xlab = "",
main = "BBMerge performance - Discarded",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Discarded"),
fill = "red",
bty = "n",
cex = 1
)
dev.off()
pdf(file.path(out_dir, "BBmerge_performance_absolute_report.pdf"), width = 24)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_join)),
col = c(color_vector, "red"),
border = NA,
ylab = "Reads Count",
xlab = "",
main = "BBMerge performance - Absolute",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Joined", "Ambiguous", "No Solution", "Discarded"),
fill = c(color_vector, "red"),
bty = "n",
cex = 1
)
dev.off()
pdf(file.path(out_dir, "BBmerge_performance_percentage_report.pdf"), width = 24)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_per)),
col = c(color_vector, "red"),
border = NA,
ylab = "Reads Percentage",
xlab = "",
main = "BBMerge performance - Percentage",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Joined", "Ambiguous", "No Solution", "Discarded"),
fill = c(color_vector, "red"),
bty = "n",
cex = 1
)
dev.off()
mergedata_join <- mergedata_join[order(-mergedata_join[, 4]), ]
pdf(file.path(out_dir, "BBmerge_performace_absolute_discarded.pdf"), width = 24)
par(mar = c(14, 4, 6, 2), xpd = TRUE) # increase the bottom margin
barplot(
t(as.matrix(mergedata_join)[,4]),
col = "red",
border = NA,
ylab = "Reads Count",
xlab = "",
main = "BBMerge performance - Discarded",
las = 2,
cex.names = 0.5,
cex.axis = 0.7,
cex.main = 2
)
mtext("Experiment ID", side = 1, line = 12) # lower x-axis label
legend(
"top",
inset=c(0,-0.1),
horiz = TRUE,
legend = c("Discarded"),
fill = "red",
bty = "n",
cex = 1
)
dev.off()
